[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Data Cleaning",
    "section": "",
    "text": "This is a webiste created by the Science and Decision Support team at the Atlas of Living Australia (ALA) to support researchers and decision makers on a consistent process of cleaning up biodiversity datasets, obtained or not from ALA.\nIn this book we will first discuss the importance and limitations of data cleaning, followed by practical guidelines and a step-by-step for data acquisition, taxonomic, distribution and ecological data clean-up and additional decisions that can improve data quality, depending of the kind of study being conducted.\nYou will also find resources and R packages that can be used to facilitate the data cleaning process. Note that there’s no work for all solution, and all guidelines should be revised according to your data and knowledge.\nThis is a free and live document. If you have questions or suggestions please reach us at (e-mail)."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "nice diagram\ndecide where to refer to the R packages\nadd references"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Boyle, B. L. 2022. “Geographic Name Resolution Service: A Tool for\nthe Standardization and Indexing of World Political Division Names, with\nApplications to Species Distribution Modeling.” bioRxiv\n27 (2): 97–111. https://doi.org/10.1101/2022.04.25.489424.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "preparation.html",
    "href": "preparation.html",
    "title": "Data download and preparation",
    "section": "",
    "text": "This section describes the initial steps and some important points that should be considered when obtaining species distribution records. It is essential an understand and familiarization with the data prior to data cleaning.\nThere are essentially two scopes of study on getting distribution data:\n\nTaxonomic: In this case, the main aim of the study is to gather data around a specific taxonomic unit. That can be a species or a community. The search is performed using the scientific and common name of the species or group of species.\n\n(include here a figure of a species map)\n\nSpatial: Here the aim is to obtain a list of all species present in a given location. In this case, the region name or area boundaries can be used to delimit the area of interest.\n\n(include here a figure of a location with different species)\nThe following five chapters focus on the initial steps on biodiversity data cleaning, but the order can be exchange according to the scope of the study being conducted. If there is a taxonomic focus, determining a naming authority should be the first step to ensure searching the correct taxa.\n\nIn Chapter 2 we highlight the importance to be careful when checking taxonomic information and we suggest different organizations that provide updated lists.\n\nIf the interested in a specific spatial region, naming authority became a secondary task, as a knowledge of taxonomy is essential to verify the data obtained.\n\nIn Chapter 3 we list ways and different fonts to obtain occurrence data.\nIn Chapter 4 we highlight common issues when merging data from multiple places.\nIn Chapter 5 is the first time you will be visualising and getting used to the available data.\nFinally, in ?sec-optional-preparation, we provide some extra steps\nOptional steps on data preparation\n\nWhen handling data from the ALA, some filters can help obtain only the type of records required for the study. Filter by “basis of record”, for example, can ensure consistency when getting data from multiple places. For example, it is possible to exclude data originating from citizen science projects or only include data from herbariums and natural history museums.\n-EXTRA: R packages that can help with data preparation?"
  },
  {
    "objectID": "intro.html#importance-of-data-cleaning",
    "href": "intro.html#importance-of-data-cleaning",
    "title": "1  Introduction",
    "section": "1.1 Importance of data cleaning",
    "text": "1.1 Importance of data cleaning\nData cleaning is a process of identifying, fixing or/and removing incorrect, doubtful, mislabeled, or incomplete data within a dataset. It is a critical step in any research on biodiversity, as it guarantees the most trustful data to perform analyses for research. The anecdote “garbage in, garbage out” reflects this idea - a study analysis is as good as the data used.\nData problems can come from many sources, from the precision of the coordinate points during collection in the field to the combination of multiple data sources, where mismatches can happen. For this reason, the data cleaning process will vary from different datasets, making it hard to point out a “work for all” solution.\nAlthough data cleaning can be time-consuming, an established and consistent process will result in quality data to be used in future analyses."
  },
  {
    "objectID": "intro.html#components",
    "href": "intro.html#components",
    "title": "1  Introduction",
    "section": "1.2 Components",
    "text": "1.2 Components\nList here the components of data cleaning."
  },
  {
    "objectID": "intro.html#limitations",
    "href": "intro.html#limitations",
    "title": "1  Introduction",
    "section": "1.4 Limitations",
    "text": "1.4 Limitations\n\nType and quality of the information available\nDifferent types of research require different data cleaning steps\netc etc"
  },
  {
    "objectID": "intro.html#how-to-use-this-book",
    "href": "intro.html#how-to-use-this-book",
    "title": "1  Introduction",
    "section": "1.5 How to use this book",
    "text": "1.5 How to use this book\nList here\nSee Knuth (1984) for additional discussion of literate programming.\nSee Boyle (2022) for additional info\n\n\n\n\nBoyle, B. L. 2022. “Geographic Name Resolution Service: A Tool for the Standardization and Indexing of World Political Division Names, with Applications to Species Distribution Modeling.” bioRxiv 27 (2): 97–111. https://doi.org/10.1101/2022.04.25.489424.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "preparation.html#determine-a-naming-authority",
    "href": "preparation.html#determine-a-naming-authority",
    "title": "2  Step 1. Data download and preparation",
    "section": "2.1 Determine a naming authority",
    "text": "2.1 Determine a naming authority\nObtaining distribution data can be done in two ways. One is when the study is focused on a specific species or community. In this case, the search is performed using the scientific and common name of the species or group of species. Another is when there is interest in obtaining a list of all species present in a given location. In this case, the region name or area boundaries can be used to delimit the area of interest.\nRegardless of the study focus, a knowledge of taxonomy is essential to verify the data obtained. For this, different organizations provide updated lists of species or even details of history and taxonomic changes.\nIn Australia, the Australian Plant Name Index (APNI) is the primary naming authority for plants. At the same time, the Australian Faunal Directory (AFD) is the main taxonomic catalog for animal species, providing a list of accepted and authoritative names as a template.\nYet, it is fundamental to understand the taxonomic history of the interest species. Changes in taxonomy, such as species split, new higher level classification (as genera), or species descriptions, highlight the importance of keeping up-to-date with taxonomic literature. This can be achieved via specialized books and scientific papers. Most taxonomic group societies released annual updates on taxonomy. The Atlas of Living Australia (ALA) can also be used to investigate taxonomic changes.\n\n2.1.1 Australian taxonomic group societies\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists"
  },
  {
    "objectID": "preparation.html#download-occurence-data",
    "href": "preparation.html#download-occurence-data",
    "title": "2  Step 1. Download and data preparation",
    "section": "2.2 Download occurence data",
    "text": "2.2 Download occurence data\nThere are many ways to obtain occurrence data of the species or region of interest. A literature search using web search engineers as Google Scholar. Data can also be obtained directly from data infrastructure websites as the Global Biodiversity Information Facility (GBIF) or from citizen science initiatives, as iNaturalist. Australia counts with ALA, an open access Australia’s biodiversity database, that aggregates data from a broad range of projects and initiatives, museum and universities, and data uploaded directly into the platform.\nAn alternative to download data directly from project websites is to use R packages created specifically for data occurence download (see list on chapter xx or below). The ALA has developed an R package exclusively to obtain data from the Atlas. Galah enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations."
  },
  {
    "objectID": "preparation.html#merge-datasets",
    "href": "preparation.html#merge-datasets",
    "title": "2  Step 1. Data download and preparation",
    "section": "2.3 Merge datasets",
    "text": "2.3 Merge datasets\nWhen combining data from multiple places, it is important to standardize the data fields and merge the data carefully, as there is chance data will be incorectly formatted or mislabeled."
  },
  {
    "objectID": "preparation.html#familiarise-yourself-with-your-data",
    "href": "preparation.html#familiarise-yourself-with-your-data",
    "title": "2  Step 1. Download and data preparation",
    "section": "2.4 Familiarise yourself with your data",
    "text": "2.4 Familiarise yourself with your data\nFamiliarise yourself with the distribution of your data. Before you get started on any data cleaning it can help to use exploraoty visuals (like plotting the data on a map) to see what it looks like. Other tools can also help for example if you’re know your dat set should only have positive values. would add an “extra step” here to fix obvious coordinate errors (sometimes the corrdinateds are just inverted)."
  },
  {
    "objectID": "preparation.html#check-your-metadata",
    "href": "preparation.html#check-your-metadata",
    "title": "2  Step 1. Download and data preparation",
    "section": "2.5 Check your metadata",
    "text": "2.5 Check your metadata\nUnderstanding your metadata provides context to the structure of the data, and how the data was collected etc. this includes check coordinate errors as missing a negative"
  },
  {
    "objectID": "preparation.html#first-look-clean-up",
    "href": "preparation.html#first-look-clean-up",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.6 First-look clean-up",
    "text": "2.6 First-look clean-up\nRemove records from doubtful sources. Sometimes the source iof the data is questionable and it’s better to discard it straight form the beginning: from drawings, photographs or multimedia objects."
  },
  {
    "objectID": "preparation.html#ala-specific",
    "href": "preparation.html#ala-specific",
    "title": "2  Step 1. Download and data preparation",
    "section": "2.8 ALA specific",
    "text": "2.8 ALA specific\nFilter by basis of record. This can be useful when downloading data or after to make sure you are only trying to clean and deal with the type of records you want. It can ensure consistency when getting data frommultiple places. Examples of basis of record filters include: exlcuding citisen science data, only including herbarium data etc"
  },
  {
    "objectID": "preparation.html#extra-r-packages-that-can-help-on-data-preparation",
    "href": "preparation.html#extra-r-packages-that-can-help-on-data-preparation",
    "title": "2  Step 1. Data download and preparation",
    "section": "2.8 EXTRA: R packages that can help on data preparation?",
    "text": "2.8 EXTRA: R packages that can help on data preparation?"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWrite names here"
  },
  {
    "objectID": "cleaning.html#text-here",
    "href": "cleaning.html#text-here",
    "title": "3  Step 2. Cleaning and correcting your data",
    "section": "3.1 Text here",
    "text": "3.1 Text here\nhere"
  },
  {
    "objectID": "improving.html#text-here",
    "href": "improving.html#text-here",
    "title": "4  Step 3. Data Enrichment",
    "section": "4.1 Text here",
    "text": "4.1 Text here\nhere"
  },
  {
    "objectID": "cleaning.html#taxonomy",
    "href": "cleaning.html#taxonomy",
    "title": "3  Step 2. Data cleaning and standardization",
    "section": "3.1 Taxonomy",
    "text": "3.1 Taxonomy\nThe following steps assume that the taxonomic history of the included species is known and correct and out-of-date names and synonymy have been fixed during the data preparation.\n\n3.1.1 Standarize scientific names\nEnsure that the spelling is correct and fix errors as they appear. It is essential to decide on a standard way to record the scientific names and be consistent. For example, it can always start with upper case and separate the names with an underline, as in “Moloch_horridus”. It is also important to check if high hierarchy taxonomic classification is correct and not missed, as family and order.\n\n\n3.1.2 Taxonomic cleaning\n\nRemove non-identifiable specimens: If a species is not discernible with checks of spelling and taxonomy, then it should be removed.\nRemove records with insufficient taxon identification: If a record is not identified down to the species level and this level of detail is needed for the study, then the record should be removed.\nRemove records with miss-identified taxonomy: Incorrectly identified species, or unrecognized species names compared to a naming authority, should be removed.\n\n\n\n3.1.3 Optional taxonomic cleaning\nThese steps can be applicable depending on the research aim.\n\nRemove non-native species: This step is a common requirement. A list can be obtained from the Global Register of Introduced and Invasive Species (GRIIS)\nRemove domesticated specimens.\nRemove extinct species.\nRemove specific taxa/life stages depending on the study: For example, if working with terrestrial data, it is necessary to remove marine taxa."
  },
  {
    "objectID": "cleaning.html#distribution-data",
    "href": "cleaning.html#distribution-data",
    "title": "3  Step 2. Cleaning and correcting your data",
    "section": "3.2 Distribution data",
    "text": "3.2 Distribution data\nhere"
  },
  {
    "objectID": "cleaning.html#ecological-data",
    "href": "cleaning.html#ecological-data",
    "title": "3  Step 2. Cleaning and correcting your data",
    "section": "3.3 Ecological data",
    "text": "3.3 Ecological data\nhere"
  },
  {
    "objectID": "improving.html#text-2",
    "href": "improving.html#text-2",
    "title": "4  Step 3. Data Enrichment",
    "section": "4.2 Text 2",
    "text": "4.2 Text 2\nhere"
  },
  {
    "objectID": "cleaning.html#distribution",
    "href": "cleaning.html#distribution",
    "title": "3  Step 2. Data cleaning and standardization",
    "section": "3.2 Distribution",
    "text": "3.2 Distribution\nNow that the taxonomic data is cleaned, it is important to plot your data on a map again and clean up the distribution data.\n\n3.2.1 Coordinates correction (or wrangling?)\nMany coordinates issues can be solved with data manipulation instead of discarding the data immediately, as they are often data entry errors. Here are some examples:\n\nCorrect flipped coordinates: Data visualizations can help to detect flipped coordinates. Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected.\nCorrect poorly formatted coordinates: Different datasets can provide coordinates in different formats, so it is crucial to correct the format of the coordinates before discarding any points.\nCorrect numerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discard the points.\nCorrect/check for records with coordinates in a different country than is listed in the country field: The coordinates could be wrong or just the country listed. Note that the country should only be changed to match the coordinates if the data is trustworthy.\nCorrect/check for records with locality but no occurrence/georeference (if possible): If you have a good locality, consider georeferencing for coordinates rather than discarding the missing data entry. If the locality is not precise, this will likely yield lower-quality data points.\n\n\n\n3.2.2 Coordinates cleaning\nAfter completing the manipulation of the coordinates, if there are still errors, consider removing the data entry:\n\nRemove records with null or missing coordinates that could not be georeferenced: It can be records missing partial or complete information. Maintaining missing values can cause errors, as many analysis do not accept missing values. If the information is not available elsewhere or an alteration of the data would deprove the entry value, consider remove it.\nRemove records with zero coordinates that could not be georeferenced: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\nRemove records plotted away from the known species distribution area: They are easily identifiable as outliers. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it worth to go back and check the literature before discard the entry. There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area.\nRemove records with low coordinate precision: Coordinate precision is vital for the accuracy of models. However, different studies may have different precision cut-offs. For example, coordinate precision below 100km represents the grain size of many macroecological analyses. Some studies have used a cut-off of spatial resolution >25,000m or precision with less than three decimal places (add a reference here). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision.\nRemove records with coordinates assigned to country and province centroids: There are many fonts that deal with centroid data, such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. This issue can happen for several reasons and sometimes can be tricky to spot. Exploratory visuals can help support findings, making it easier to spot clusterings of points. Centroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such. In a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, therefore, should be checked and (possibly) removed."
  },
  {
    "objectID": "cleaning.html#ecology",
    "href": "cleaning.html#ecology",
    "title": "3  Step 2. Data cleaning and standardization",
    "section": "3.3 Ecology",
    "text": "3.3 Ecology\nWhen the information on the ecological requirements of the species is available and important for the study, ecological data checking, cleaning and standardization is necessary. Examples include morphological measurements that should be in the same metric, information regarding life stages, and habitat preference."
  },
  {
    "objectID": "intro.html#expect-result",
    "href": "intro.html#expect-result",
    "title": "1  Introduction",
    "section": "1.3 Expect result",
    "text": "1.3 Expect result\nA data that is: - accurate - comprehensive - consistent - relevant - uniform"
  },
  {
    "objectID": "preparation.html#initial-clean-up",
    "href": "preparation.html#initial-clean-up",
    "title": "Data download and preparation",
    "section": "Initial clean-up",
    "text": "Initial clean-up\nAlthough systematic data cleaning is required, some apparent mistakes observed during the initial visualization of the data and metadata can be fixed straight away. It includes removing records from unlikely sources, removing unnecessary details for the study, and fixing typos, incorrect capitalization and minor coordinates errors, such as inverted coordinates."
  },
  {
    "objectID": "preparation.html#rebuild-missing-data",
    "href": "preparation.html#rebuild-missing-data",
    "title": "Data download and preparation",
    "section": "Rebuild missing data??",
    "text": "Rebuild missing data??"
  },
  {
    "objectID": "intro.html#characteristics-of-a-quality-data",
    "href": "intro.html#characteristics-of-a-quality-data",
    "title": "1  Introduction",
    "section": "1.2 Characteristics of a quality data",
    "text": "1.2 Characteristics of a quality data\n\nAccurate. describe here\nComprehensive. describe here\nConsistent. describe here\nRelevant. describe here\nUniform. describe here\n\nfrom (https://www.iteratorshq.com/blog/data-cleaning-in-5-easy-steps/)"
  },
  {
    "objectID": "intro.html#data-cleaning-process",
    "href": "intro.html#data-cleaning-process",
    "title": "1  Introduction",
    "section": "1.3 Data cleaning process",
    "text": "1.3 Data cleaning process\nIn the following chapters, we will dive deep into the different steps of the data-cleaning process. It can be separated into three main steps: Data preparation, standardization, and enrichment (Figure 1).\n\n\n\nFigure 1. Data cleaning process"
  },
  {
    "objectID": "intro.html#importance-of-data-cceaning",
    "href": "intro.html#importance-of-data-cceaning",
    "title": "1  Introduction",
    "section": "1.1 Importance of data Cceaning",
    "text": "1.1 Importance of data Cceaning\nData cleaning is a process of identifying, fixing or/and removing incorrect, doubtful, mislabeled, or incomplete data within a dataset. It is a critical step in any research on biodiversity, as it guarantees the most trustful data to perform analyses for research. The anecdote “garbage in, garbage out” reflects this idea - a study analysis is as good as the data used.\nData problems can come from many sources, from the precision of the coordinate points during collection in the field to the combination of multiple data sources, where mismatches can happen. For this reason, the data cleaning process will vary from different datasets, making it hard to point out a “work for all” solution.\nAlthough data cleaning can be time-consuming, an established and consistent process will result in quality data to be used in future analyses."
  },
  {
    "objectID": "preparation.html#download-occurrence-data",
    "href": "preparation.html#download-occurrence-data",
    "title": "2  Step 1. Data download and preparation",
    "section": "2.2 Download occurrence data",
    "text": "2.2 Download occurrence data\nThere are many ways to obtain species or region of interest occurrence data. A literature search using web search engineers such as Google Scholar. Data can also be obtained directly from data infrastructure websites such as the Global Biodiversity Information Facility (GBIF) or citizen science initiatives, such as iNaturalist. Australia counts on ALA, an open-access Australia’s biodiversity database that aggregates data from a broad range of projects and initiatives, museums and universities, and data uploaded directly into the platform.\nAn alternative to downloading data directly from project websites is to use R packages explicitly created for data occurrence download (see a list in chapter xx or below). The ALA has developed an R package exclusively to obtain data from ALA. Galah enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations."
  },
  {
    "objectID": "preparation.html#familiarise-with-the-data-and-metadata",
    "href": "preparation.html#familiarise-with-the-data-and-metadata",
    "title": "Data download and preparation",
    "section": "Familiarise with the data and metadata",
    "text": "Familiarise with the data and metadata\nBefore getting started with data cleaning, a visual inspection of the entire dataset can save time and solve easy-to-spot errors. It can improve the knowledge of the available data and can be done with it. Understanding the metadata provides context to the structure of the data and information on how the data was collected.\nA plot of the occurrence data on a map can follow it. This simple step can highlight coordinates with missing data or even inverted or erroneous coordinates (as points floating in the ocean while focusing on terrestrial species and vice versa).\nOther tools, such as looking for only positive values if that is what is expected, can also be used in this initial data familiarization step."
  },
  {
    "objectID": "preparation.html#optional-steps-on-data-preparation",
    "href": "preparation.html#optional-steps-on-data-preparation",
    "title": "Data download and preparation",
    "section": "Optional steps on data preparation",
    "text": "Optional steps on data preparation\nWhen handling data from the ALA, some filters can help obtain only the type of records required for the study. Filter by “basis of record”, for example, can ensure consistency when getting data from multiple places. For example, it is possible to exclude data originating from citizen science projects or only include data from herbariums and natural history museums."
  },
  {
    "objectID": "cleaning.html#taxonomic-cleaning",
    "href": "cleaning.html#taxonomic-cleaning",
    "title": "3  Step 2. Data standarization",
    "section": "3.2 Taxonomic cleaning",
    "text": "3.2 Taxonomic cleaning\n\nRemove non-identifiable specimens: If a species is not discernible with checks of spelling etc then it should be removed\nRemove records with insufficient taxon identification: If a record is not identified down to the species level and this level of detail is needed then the record should be removed\nRemove records with mis-identified taxonomy: Incorrectly identified species, or unrecognised species name compared to a naming authority\n\n\n3.2.1 Optional taxonomic cleaning\nThis steps can be applicable depending on your research aim.\n\nRemove non-native species: This will be dependant on the type of study you’re conducting, however it’s a common requirement- this GRIIS list can be used for this in Australia\nRemove domesticated specimens\nRemove extinct species\nRemove specific taxa/lifestages depending on study: for example marine taxa or non-vascualr plants. Marine taxa can be difficult as at the ALA for example we do not have a way of discerning marine species so this is often tedious-especially when looking at all life stages"
  },
  {
    "objectID": "example.html",
    "href": "example.html",
    "title": "5  Work Example",
    "section": "",
    "text": "Include here an workable example (maybe using galah?)"
  },
  {
    "objectID": "cleaning.html#checklist-of-data-standarization",
    "href": "cleaning.html#checklist-of-data-standarization",
    "title": "3  Step 2. Data cleaning and standardization",
    "section": "3.4 Checklist of data standarization",
    "text": "3.4 Checklist of data standarization\nAdd here a downloadable checklist of issues to be checked"
  },
  {
    "objectID": "improving.html",
    "href": "improving.html",
    "title": "Data Enrichment",
    "section": "",
    "text": "Now that the data is cleaned and standardized, extra work can be done to guarantee the data quality. These steps will depend on the kind of study being conducted.\n\nRemove duplicates: Data duplication is common when combining data from multiple sources. In most part of the cases, you will want to remove duplicate data, as it just increase you data size without bringing in any relevant information. It can also make analysis faster and more efficient.\nBias correction: Account for sampling bias.\nScrutinise outliers: Outliers can be true outliers or data errors. True outliers are not necessarily to be removed. This could represent misidentified specimens, etc.\nFormat data: Subset, specify data source as ALA, indicate sensitive species, assign habitat column, rearrange and name columns.\nStudy region: Important if you need to crop data to the region or to work out the current range, background region, and projection region.\nAssign quality levels to data: If you need help with specific data, assigning quality level metrics for taxonomy and geographical dimensions can be good.\nManually identify and remove false positives: False positives that may have been overlooked by automated error removal, based on the knowledge that they are in the records.\nRemove records with an individual count of less than 1 or more than 99: Records may be unsuitable if the number of recorded individuals is 0 or the count is too high (data entry or data-basing problems), indicate records from dna barcoding and in some cases indicate records of absence.\nConsider species with fewer records: Depending of the the type of analysis to be conducted, as in the case of Species Distribution Modelling, the number of distribution points available can influence the quality of the results.\nReach out and ask questions: When preparing occurrence data for modeling it can be helpful to speak to experts in the field."
  },
  {
    "objectID": "preparation.html#extra-r-packages-that-can-help-with-data-preparation",
    "href": "preparation.html#extra-r-packages-that-can-help-with-data-preparation",
    "title": "Data download and preparation",
    "section": "EXTRA: R packages that can help with data preparation?",
    "text": "EXTRA: R packages that can help with data preparation?"
  },
  {
    "objectID": "cleaning.html#checklist-of-data-standardization",
    "href": "cleaning.html#checklist-of-data-standardization",
    "title": "Data cleaning and standardization",
    "section": "Checklist of data standardization",
    "text": "Checklist of data standardization\nAdd here a downloadable checklist of issues to be checked."
  },
  {
    "objectID": "cleaning.html#spatial-data",
    "href": "cleaning.html#spatial-data",
    "title": "3  Step 2. Data cleaning and standardization",
    "section": "3.2 Spatial data",
    "text": "3.2 Spatial data\nNow that the taxonomic data is cleaned, it is important to plot your data on a map again and clean up the distribution data.\n\n3.2.1 Coordinates correction (or wrangling?)\nMany coordinates issues can be solved with data manipulation instead of discarding the data immediately, as they are often data entry errors. Here are some examples:\n\nCorrect flipped coordinates: Data visualizations can help to detect flipped coordinates. Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected.\nCorrect poorly formatted coordinates: Different datasets can provide coordinates in different formats, so it is crucial to correct the format of the coordinates before discarding any points.\nCorrect numerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discard the points.\nCorrect/check for records with coordinates in a different country than is listed in the country field: The coordinates could be wrong or just the country listed. Note that the country should only be changed to match the coordinates if the data is trustworthy.\nCorrect/check for records with locality but no occurrence/georeference (if possible): If you have a good locality, consider georeferencing for coordinates rather than discarding the missing data entry. If the locality is not precise, this will likely yield lower-quality data points.\n\n\n\n3.2.2 Coordinates cleaning\nAfter completing the manipulation of the coordinates, if there are still errors, consider removing the data entry:\n\nRemove records with null or missing coordinates that could not be georeferenced: It can be records missing partial or complete information. Maintaining missing values can cause errors, as many analysis do not accept missing values. If the information is not available elsewhere or an alteration of the data would deprove the entry value, consider remove it.\nRemove records with zero coordinates that could not be georeferenced: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\nRemove records plotted away from the known species distribution area: They are easily identifiable as outliers. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it worth to go back and check the literature before discard the entry. There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area.\nRemove records with low coordinate precision: Coordinate precision is vital for the accuracy of models. However, different studies may have different precision cut-offs. For example, coordinate precision below 100km represents the grain size of many macroecological analyses. Some studies have used a cut-off of spatial resolution >25,000m or precision with less than three decimal places (add a reference here). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision.\nRemove records with coordinates assigned to country and province centroids: There are many fonts that deal with centroid data, such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. This issue can happen for several reasons and sometimes can be tricky to spot. Exploratory visuals can help support findings, making it easier to spot clusterings of points. Centroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such. In a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, therefore, should be checked and (possibly) removed."
  },
  {
    "objectID": "index.html#how-to-cite-this-book",
    "href": "index.html#how-to-cite-this-book",
    "title": "ALA Data Cleaning",
    "section": "How to cite this book",
    "text": "How to cite this book"
  },
  {
    "objectID": "naming-authority.html#download-occurrence-data",
    "href": "naming-authority.html#download-occurrence-data",
    "title": "2  Determine a naming authority",
    "section": "2.1 Download occurrence data",
    "text": "2.1 Download occurrence data\nThere are many ways to obtain species or region of interest occurrence data. A literature search using web search engineers such as Google Scholar. Data can also be obtained directly from data infrastructure websites such as the Global Biodiversity Information Facility (GBIF) or citizen science initiatives, such as iNaturalist. Australia counts on ALA, an open-access Australia’s biodiversity database that aggregates data from a broad range of projects and initiatives, museums and universities, and data uploaded directly into the platform.\nAn alternative to downloading data directly from project websites is to use R packages explicitly created for data occurrence download (see a list in chapter xx or below). The ALA has developed an R package exclusively to obtain data from ALA. Galah enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations."
  },
  {
    "objectID": "naming-authority.html#merge-datasets",
    "href": "naming-authority.html#merge-datasets",
    "title": "2  Determine a naming authority",
    "section": "2.2 Merge datasets",
    "text": "2.2 Merge datasets\nWhen combining data from multiple places, it is important to standardize the data fields and merge the data carefully, as there is chance data will be incorectly formatted or mislabeled.\n\ndiscuss here biosec issues, higher taxonomy is not always the same;"
  },
  {
    "objectID": "naming-authority.html#familiarise-with-the-data-and-metadata",
    "href": "naming-authority.html#familiarise-with-the-data-and-metadata",
    "title": "2  Determine a naming authority",
    "section": "2.3 Familiarise with the data and metadata",
    "text": "2.3 Familiarise with the data and metadata\nBefore getting started with data cleaning, a visual inspection of the entire dataset can save time and solve easy-to-spot errors. It can improve the knowledge of the available data and can be done with it. Understanding the metadata provides context to the structure of the data and information on how the data was collected.\nA plot of the occurrence data on a map can follow it. This simple step can highlight coordinates with missing data or even inverted or erroneous coordinates (as points floating in the ocean while focusing on terrestrial species and vice versa).\nOther tools, such as looking for only positive values if that is what is expected, can also be used in this initial data familiarization step."
  },
  {
    "objectID": "naming-authority.html#initial-clean-up",
    "href": "naming-authority.html#initial-clean-up",
    "title": "2  Determine a naming authority",
    "section": "2.4 Initial clean-up",
    "text": "2.4 Initial clean-up\nAlthough systematic data cleaning is required, some apparent mistakes observed during the initial visualization of the data and metadata can be fixed straight away. It includes removing records from unlikely sources, removing unnecessary details for the study, and fixing typos, incorrect capitalization and minor coordinates errors, such as inverted coordinates."
  },
  {
    "objectID": "naming-authority.html#rebuild-missing-data",
    "href": "naming-authority.html#rebuild-missing-data",
    "title": "2  Determine a naming authority",
    "section": "2.5 Rebuild missing data??",
    "text": "2.5 Rebuild missing data??"
  },
  {
    "objectID": "naming-authority.html#optional-steps-on-data-preparation",
    "href": "naming-authority.html#optional-steps-on-data-preparation",
    "title": "2  Determine a naming authority",
    "section": "2.6 Optional steps on data preparation",
    "text": "2.6 Optional steps on data preparation\nWhen handling data from the ALA, some filters can help obtain only the type of records required for the study. Filter by “basis of record”, for example, can ensure consistency when getting data from multiple places. For example, it is possible to exclude data originating from citizen science projects or only include data from herbariums and natural history museums."
  },
  {
    "objectID": "naming-authority.html#extra-r-packages-that-can-help-with-data-preparation",
    "href": "naming-authority.html#extra-r-packages-that-can-help-with-data-preparation",
    "title": "2  Determine a naming authority",
    "section": "2.7 EXTRA: R packages that can help with data preparation?",
    "text": "2.7 EXTRA: R packages that can help with data preparation?"
  },
  {
    "objectID": "download-data.html#merge-datasets",
    "href": "download-data.html#merge-datasets",
    "title": "3  Download occurrence data",
    "section": "3.1 Merge datasets",
    "text": "3.1 Merge datasets\nWhen combining data from multiple places, it is important to standardize the data fields and merge the data carefully, as there is chance data will be incorectly formatted or mislabeled.\n\ndiscuss here biosec issues, higher taxonomy is not always the same;"
  },
  {
    "objectID": "download-data.html#familiarise-with-the-data-and-metadata",
    "href": "download-data.html#familiarise-with-the-data-and-metadata",
    "title": "3  Download occurrence data",
    "section": "3.2 Familiarise with the data and metadata",
    "text": "3.2 Familiarise with the data and metadata\nBefore getting started with data cleaning, a visual inspection of the entire dataset can save time and solve easy-to-spot errors. It can improve the knowledge of the available data and can be done with it. Understanding the metadata provides context to the structure of the data and information on how the data was collected.\nA plot of the occurrence data on a map can follow it. This simple step can highlight coordinates with missing data or even inverted or erroneous coordinates (as points floating in the ocean while focusing on terrestrial species and vice versa).\nOther tools, such as looking for only positive values if that is what is expected, can also be used in this initial data familiarization step."
  },
  {
    "objectID": "download-data.html#initial-clean-up",
    "href": "download-data.html#initial-clean-up",
    "title": "3  Download occurrence data",
    "section": "3.3 Initial clean-up",
    "text": "3.3 Initial clean-up\nAlthough systematic data cleaning is required, some apparent mistakes observed during the initial visualization of the data and metadata can be fixed straight away. It includes removing records from unlikely sources, removing unnecessary details for the study, and fixing typos, incorrect capitalization and minor coordinates errors, such as inverted coordinates."
  },
  {
    "objectID": "download-data.html#rebuild-missing-data",
    "href": "download-data.html#rebuild-missing-data",
    "title": "3  Download occurrence data",
    "section": "3.4 Rebuild missing data??",
    "text": "3.4 Rebuild missing data??"
  },
  {
    "objectID": "download-data.html#optional-steps-on-data-preparation",
    "href": "download-data.html#optional-steps-on-data-preparation",
    "title": "3  Download occurrence data",
    "section": "3.5 Optional steps on data preparation",
    "text": "3.5 Optional steps on data preparation\nWhen handling data from the ALA, some filters can help obtain only the type of records required for the study. Filter by “basis of record”, for example, can ensure consistency when getting data from multiple places. For example, it is possible to exclude data originating from citizen science projects or only include data from herbariums and natural history museums."
  },
  {
    "objectID": "download-data.html#extra-r-packages-that-can-help-with-data-preparation",
    "href": "download-data.html#extra-r-packages-that-can-help-with-data-preparation",
    "title": "3  Download occurrence data",
    "section": "3.6 EXTRA: R packages that can help with data preparation?",
    "text": "3.6 EXTRA: R packages that can help with data preparation?"
  },
  {
    "objectID": "merge-data.html#familiarise-with-the-data-and-metadata",
    "href": "merge-data.html#familiarise-with-the-data-and-metadata",
    "title": "4  Merge datasets",
    "section": "4.1 Familiarise with the data and metadata",
    "text": "4.1 Familiarise with the data and metadata\nBefore getting started with data cleaning, a visual inspection of the entire dataset can save time and solve easy-to-spot errors. It can improve the knowledge of the available data and can be done with it. Understanding the metadata provides context to the structure of the data and information on how the data was collected.\nA plot of the occurrence data on a map can follow it. This simple step can highlight coordinates with missing data or even inverted or erroneous coordinates (as points floating in the ocean while focusing on terrestrial species and vice versa).\nOther tools, such as looking for only positive values if that is what is expected, can also be used in this initial data familiarization step."
  },
  {
    "objectID": "merge-data.html#initial-clean-up",
    "href": "merge-data.html#initial-clean-up",
    "title": "4  Merge datasets",
    "section": "4.2 Initial clean-up",
    "text": "4.2 Initial clean-up\nAlthough systematic data cleaning is required, some apparent mistakes observed during the initial visualization of the data and metadata can be fixed straight away. It includes removing records from unlikely sources, removing unnecessary details for the study, and fixing typos, incorrect capitalization and minor coordinates errors, such as inverted coordinates."
  },
  {
    "objectID": "merge-data.html#rebuild-missing-data",
    "href": "merge-data.html#rebuild-missing-data",
    "title": "4  Merge datasets",
    "section": "4.3 Rebuild missing data??",
    "text": "4.3 Rebuild missing data??"
  },
  {
    "objectID": "merge-data.html#optional-steps-on-data-preparation",
    "href": "merge-data.html#optional-steps-on-data-preparation",
    "title": "4  Merge datasets",
    "section": "4.4 Optional steps on data preparation",
    "text": "4.4 Optional steps on data preparation\nWhen handling data from the ALA, some filters can help obtain only the type of records required for the study. Filter by “basis of record”, for example, can ensure consistency when getting data from multiple places. For example, it is possible to exclude data originating from citizen science projects or only include data from herbariums and natural history museums."
  },
  {
    "objectID": "merge-data.html#extra-r-packages-that-can-help-with-data-preparation",
    "href": "merge-data.html#extra-r-packages-that-can-help-with-data-preparation",
    "title": "4  Merge datasets",
    "section": "4.5 EXTRA: R packages that can help with data preparation?",
    "text": "4.5 EXTRA: R packages that can help with data preparation?"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "ALA Data Cleaning",
    "section": "Citation",
    "text": "Citation\n(include the book citation here)\nParticipants, in alphabetic order:\n- Fonti Kar\n- Jessica Fenker\n- Margot Schneider\n- Martin Westgate"
  },
  {
    "objectID": "familiarise-data.html#initial-clean-up",
    "href": "familiarise-data.html#initial-clean-up",
    "title": "5  Familiarise with the data and metadata and initial clean-up",
    "section": "5.1 Initial clean-up",
    "text": "5.1 Initial clean-up\nAlthough systematic data cleaning is required, some apparent mistakes observed during the initial visualization of the data and metadata can be fixed straight away. It includes removing records from unlikely sources, removing unnecessary details for the study, and fixing typos, incorrect capitalization and minor coordinates errors, such as inverted coordinates."
  },
  {
    "objectID": "familiarise-data.html#rebuild-missing-data",
    "href": "familiarise-data.html#rebuild-missing-data",
    "title": "5  Familiarise with the data and metadata and initial clean-up",
    "section": "5.2 Rebuild missing data??",
    "text": "5.2 Rebuild missing data??"
  },
  {
    "objectID": "familiarise-data.html#optional-steps-on-data-preparation",
    "href": "familiarise-data.html#optional-steps-on-data-preparation",
    "title": "5  Familiarise with the data and metadata and initial clean-up",
    "section": "5.3 Optional steps on data preparation",
    "text": "5.3 Optional steps on data preparation\nWhen handling data from the ALA, some filters can help obtain only the type of records required for the study. Filter by “basis of record”, for example, can ensure consistency when getting data from multiple places. For example, it is possible to exclude data originating from citizen science projects or only include data from herbariums and natural history museums."
  },
  {
    "objectID": "familiarise-data.html#extra-r-packages-that-can-help-with-data-preparation",
    "href": "familiarise-data.html#extra-r-packages-that-can-help-with-data-preparation",
    "title": "5  Familiarise with the data and metadata and initial clean-up",
    "section": "5.4 EXTRA: R packages that can help with data preparation?",
    "text": "5.4 EXTRA: R packages that can help with data preparation?"
  },
  {
    "objectID": "spatial.html#ecology",
    "href": "spatial.html#ecology",
    "title": "7  Spatial data",
    "section": "7.1 Ecology",
    "text": "7.1 Ecology\nWhen the information on the ecological requirements of the species is available and important for the study, ecological data checking, cleaning and standardization is necessary. Examples include morphological measurements that should be in the same metric, information regarding life stages, and habitat preference."
  },
  {
    "objectID": "spatial.html#checklist-of-data-standardization",
    "href": "spatial.html#checklist-of-data-standardization",
    "title": "7  Spatial data",
    "section": "7.2 Checklist of data standardization",
    "text": "7.2 Checklist of data standardization\nAdd here a downloadable checklist of issues to be checked."
  },
  {
    "objectID": "ecological.html#checklist-of-data-standardization",
    "href": "ecological.html#checklist-of-data-standardization",
    "title": "8  Ecology",
    "section": "8.1 Checklist of data standardization",
    "text": "8.1 Checklist of data standardization\nAdd here a downloadable checklist of issues to be checked."
  },
  {
    "objectID": "taxonomic.html#spatial-data",
    "href": "taxonomic.html#spatial-data",
    "title": "6  Taxonomy",
    "section": "6.1 Spatial data",
    "text": "6.1 Spatial data\nNow that the taxonomic data is cleaned, it is important to plot your data on a map again and clean up the distribution data.\n\n6.1.1 Coordinates correction (or wrangling?)\nMany coordinates issues can be solved with data manipulation instead of discarding the data immediately, as they are often data entry errors. Here are some examples:\n\nCorrect flipped coordinates: Data visualizations can help to detect flipped coordinates. Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected.\nCorrect poorly formatted coordinates: Different datasets can provide coordinates in different formats, so it is crucial to correct the format of the coordinates before discarding any points.\nCorrect numerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discard the points.\nCorrect/check for records with coordinates in a different country than is listed in the country field: The coordinates could be wrong or just the country listed. Note that the country should only be changed to match the coordinates if the data is trustworthy.\nCorrect/check for records with locality but no occurrence/georeference (if possible): If you have a good locality, consider georeferencing for coordinates rather than discarding the missing data entry. If the locality is not precise, this will likely yield lower-quality data points.\n\n\n\n6.1.2 Coordinates cleaning\nAfter completing the manipulation of the coordinates, if there are still errors, consider removing the data entry:\n\nRemove records with null or missing coordinates that could not be georeferenced: It can be records missing partial or complete information. Maintaining missing values can cause errors, as many analysis do not accept missing values. If the information is not available elsewhere or an alteration of the data would deprove the entry value, consider remove it.\nRemove records with zero coordinates that could not be georeferenced: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\nRemove records plotted away from the known species distribution area: They are easily identifiable as outliers. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it worth to go back and check the literature before discard the entry. There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area.\nRemove records with low coordinate precision: Coordinate precision is vital for the accuracy of models. However, different studies may have different precision cut-offs. For example, coordinate precision below 100km represents the grain size of many macroecological analyses. Some studies have used a cut-off of spatial resolution >25,000m or precision with less than three decimal places (add a reference here). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision.\nRemove records with coordinates assigned to country and province centroids: There are many fonts that deal with centroid data, such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. This issue can happen for several reasons and sometimes can be tricky to spot. Exploratory visuals can help support findings, making it easier to spot clusterings of points. Centroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such. In a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, therefore, should be checked and (possibly) removed."
  },
  {
    "objectID": "taxonomic.html#ecology",
    "href": "taxonomic.html#ecology",
    "title": "6  Taxonomy",
    "section": "6.2 Ecology",
    "text": "6.2 Ecology\nWhen the information on the ecological requirements of the species is available and important for the study, ecological data checking, cleaning and standardization is necessary. Examples include morphological measurements that should be in the same metric, information regarding life stages, and habitat preference."
  },
  {
    "objectID": "taxonomic.html#checklist-of-data-standardization",
    "href": "taxonomic.html#checklist-of-data-standardization",
    "title": "6  Taxonomy",
    "section": "6.3 Checklist of data standardization",
    "text": "6.3 Checklist of data standardization\nAdd here a downloadable checklist of issues to be checked."
  },
  {
    "objectID": "cleaning.html",
    "href": "cleaning.html",
    "title": "Data cleaning and standardization",
    "section": "",
    "text": "This section describes how to clean and correct the dataset, divided into three main sections: taxonomy, distribution, and ecology.\nIn Chapter 6\nThe following steps assume that the taxonomic history of the included species is known and correct and out-of-date names and synonymy have been fixed during the data preparation.\nStandarize scientific names\nEnsure that the spelling is correct and fix errors as they appear. It is essential to decide on a standard way to record the scientific names and be consistent. For example, it can always start with upper case and separate the names with an underline, as in “Moloch_horridus”. It is also important to check if high hierarchy taxonomic classification is correct and not missed, as family and order.\nTaxonomic cleaning\n\nRemove non-identifiable specimens: If a species is not discernible with checks of spelling and taxonomy, then it should be removed.\nRemove records with insufficient taxon identification: If a record is not identified down to the species level and this level of detail is needed for the study, then the record should be removed.\nRemove records with miss-identified taxonomy: Incorrectly identified species, or unrecognized species names compared to a naming authority, should be removed.\n\nOptional taxonomic cleaning\nThese steps can be applicable depending on the research aim.\n\nRemove non-native species: This step is a common requirement. A list can be obtained from the Global Register of Introduced and Invasive Species (GRIIS)\nRemove domesticated specimens.\nRemove extinct species.\nRemove specific taxa/life stages depending on the study: For example, if working with terrestrial data, it is necessary to remove marine taxa.\n\nIn Chapter 7\nNow that the taxonomic data is cleaned, it is important to plot your data on a map again and clean up the distribution data.\nCoordinates correction (or wrangling?)\nMany coordinates issues can be solved with data manipulation instead of discarding the data immediately, as they are often data entry errors. Here are some examples:\n\nCorrect flipped coordinates: Data visualizations can help to detect flipped coordinates. Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected.\nCorrect poorly formatted coordinates: Different datasets can provide coordinates in different formats, so it is crucial to correct the format of the coordinates before discarding any points.\nCorrect numerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discard the points.\nCorrect/check for records with coordinates in a different country than is listed in the country field: The coordinates could be wrong or just the country listed. Note that the country should only be changed to match the coordinates if the data is trustworthy.\nCorrect/check for records with locality but no occurrence/georeference (if possible): If you have a good locality, consider georeferencing for coordinates rather than discarding the missing data entry. If the locality is not precise, this will likely yield lower-quality data points.\n\nCoordinates cleaning\nAfter completing the manipulation of the coordinates, if there are still errors, consider removing the data entry:\n\nRemove records with null or missing coordinates that could not be georeferenced: It can be records missing partial or complete information. Maintaining missing values can cause errors, as many analysis do not accept missing values. If the information is not available elsewhere or an alteration of the data would deprove the entry value, consider remove it.\nRemove records with zero coordinates that could not be georeferenced: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\nRemove records plotted away from the known species distribution area: They are easily identifiable as outliers. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it worth to go back and check the literature before discard the entry. There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area.\nRemove records with low coordinate precision: Coordinate precision is vital for the accuracy of models. However, different studies may have different precision cut-offs. For example, coordinate precision below 100km represents the grain size of many macroecological analyses. Some studies have used a cut-off of spatial resolution >25,000m or precision with less than three decimal places (add a reference here). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision.\nRemove records with coordinates assigned to country and province centroids: There are many fonts that deal with centroid data, such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. This issue can happen for several reasons and sometimes can be tricky to spot. Exploratory visuals can help support findings, making it easier to spot clusterings of points. Centroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such. In a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, therefore, should be checked and (possibly) removed.\n\nIn Chapter 8\nWhen the information on the ecological requirements of the species is available and important for the study, ecological data checking, cleaning and standardization is necessary. Examples include morphological measurements that should be in the same metric, information regarding life stages, and habitat preference.\nChecklist of data standardization\nAdd here a downloadable checklist of issues to be checked."
  }
]