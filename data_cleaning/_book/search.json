[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Data Cleaning",
    "section": "",
    "text": "This is a book created by the Science and Decision Support team at the Atlas of Living Australia (ALA) to support researchers and decision makers on a consistent process of cleaning up biodiversity datasets, obtained or not from ALA.\nThis is a free and live document. If you have questions or suggestions please reach us at (e-mail)."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "preparation.html",
    "href": "preparation.html",
    "title": "2  Preparation",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "intro.html#importance-of-data-cleaning",
    "href": "intro.html#importance-of-data-cleaning",
    "title": "1  Introduction",
    "section": "1.1 Importance of data cleaning",
    "text": "1.1 Importance of data cleaning\nData cleaning is a process of identifying, fixing or/and removing incorrect, doubtful, mislabeled, or incomplete data within a dataset. It is a critical step in any research on biodiversity, as it guarantees the most trustful data to perform analyses for research. The anecdote “garbage in, garbage out” reflects this idea - a study analysis is as good as the data used.\nData problems can come from many sources, from the precision of the coordinate points during collection in the field to the combination of multiple data sources, where mismatches can happen. For this reason, the data cleaning process will vary from different datasets, making it hard to point out a “work for all” solution.\nAlthough data cleaning can be time-consuming, an established and consistent process will result in quality data to be used in future analyses."
  },
  {
    "objectID": "intro.html#components",
    "href": "intro.html#components",
    "title": "1  Introduction",
    "section": "1.2 Components",
    "text": "1.2 Components\nList here the components of data cleaning."
  },
  {
    "objectID": "intro.html#limitations",
    "href": "intro.html#limitations",
    "title": "1  Introduction",
    "section": "1.4 Limitations",
    "text": "1.4 Limitations\n\nType and quality of the information available\nDifferent types of research require different data cleaning steps\netc etc"
  },
  {
    "objectID": "intro.html#how-to-use-this-book",
    "href": "intro.html#how-to-use-this-book",
    "title": "1  Introduction",
    "section": "1.5 How to use this book",
    "text": "1.5 How to use this book\nList here\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "preparation.html#determine-a-naming-authority",
    "href": "preparation.html#determine-a-naming-authority",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.1 Determine a naming authority",
    "text": "2.1 Determine a naming authority\nYour study can focus on a species or community or maybe you are interested on all species that can occur within a region. Independent of it, a taxonomic name check is fundamental.\nIn Australia for plants people use APC (with APNI) for animals AFD-this provides a list of accepted and authoritative name which can be used as a template.\nBook and papers can also be fundamental to understand taxonomic history. Remember that sometimes the names are just not up to date - it worth to check possible alternatives and double-check the original paper instead of just elimitate a data point. Also, taxonomic groups societies (e.g. ASH) can provide up-to-date lists.\n\n2.1.1 EXTRA: taxonomic group societies links\nASH - link"
  },
  {
    "objectID": "preparation.html#download-occurence-data",
    "href": "preparation.html#download-occurence-data",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.2 Download occurence data",
    "text": "2.2 Download occurence data\nbe careful here with possible taxonomic limitations - know your data"
  },
  {
    "objectID": "preparation.html#merge-datasets",
    "href": "preparation.html#merge-datasets",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.3 Merge datasets",
    "text": "2.3 Merge datasets\nIf you’ve collected data from multiple places, It’s important to standardise and collate it"
  },
  {
    "objectID": "preparation.html#familiarise-yourself-with-your-data",
    "href": "preparation.html#familiarise-yourself-with-your-data",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.4 Familiarise yourself with your data",
    "text": "2.4 Familiarise yourself with your data\nFamiliarise yourself with the distribution of your data. Before you get started on any data cleaning it can help to use exploraoty visuals (like plotting the data on a map) to see what it looks like. Other tools can also help for example if you’re know your dat set should only have positive values. would add an “extra step” here to fix obvious coordinate errors (sometimes the corrdinateds are just inverted)."
  },
  {
    "objectID": "preparation.html#check-your-metadata",
    "href": "preparation.html#check-your-metadata",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.5 Check your metadata",
    "text": "2.5 Check your metadata\nUnderstanding your metadata provides context to the structure of the data, and how the data was collected etc. this includes check coordinate errors as missing a negative"
  },
  {
    "objectID": "preparation.html#first-look-clean-up",
    "href": "preparation.html#first-look-clean-up",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.6 First-look clean-up",
    "text": "2.6 First-look clean-up\nRemove records from doubtful sources. Sometimes the source iof the data is questionable and it’s better to discard it straight form the beginning: from drawings, photographs or multimedia objects."
  },
  {
    "objectID": "preparation.html#ala-specific",
    "href": "preparation.html#ala-specific",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.8 ALA specific",
    "text": "2.8 ALA specific\nFilter by basis of record. This can be useful when downloading data or after to make sure you are only trying to clean and deal with the type of records you want. It can ensure consistency when getting data frommultiple places. Examples of basis of record filters include: exlcuding citisen science data, only including herbarium data etc"
  },
  {
    "objectID": "preparation.html#extra-r-packages-that-can-help-on-data-preparation",
    "href": "preparation.html#extra-r-packages-that-can-help-on-data-preparation",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.9 EXTRA: R packages that can help on data preparation?",
    "text": "2.9 EXTRA: R packages that can help on data preparation?"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWrite names here"
  },
  {
    "objectID": "cleaning.html#text-here",
    "href": "cleaning.html#text-here",
    "title": "3  Step 2. Cleaning and correcting your data",
    "section": "3.1 Text here",
    "text": "3.1 Text here\nhere"
  },
  {
    "objectID": "improving.html#text-here",
    "href": "improving.html#text-here",
    "title": "4  Step 3. Improving your data",
    "section": "4.1 Text here",
    "text": "4.1 Text here\nhere"
  },
  {
    "objectID": "cleaning.html#taxonomy",
    "href": "cleaning.html#taxonomy",
    "title": "3  Step 2. Standarizing your data",
    "section": "3.1 Taxonomy",
    "text": "3.1 Taxonomy\nhere"
  },
  {
    "objectID": "cleaning.html#distribution-data",
    "href": "cleaning.html#distribution-data",
    "title": "3  Step 2. Cleaning and correcting your data",
    "section": "3.2 Distribution data",
    "text": "3.2 Distribution data\nhere"
  },
  {
    "objectID": "cleaning.html#ecological-data",
    "href": "cleaning.html#ecological-data",
    "title": "3  Step 2. Cleaning and correcting your data",
    "section": "3.3 Ecological data",
    "text": "3.3 Ecological data\nhere"
  },
  {
    "objectID": "improving.html#text-2",
    "href": "improving.html#text-2",
    "title": "4  Step 3. Improving your data",
    "section": "4.2 Text 2",
    "text": "4.2 Text 2\nhere"
  },
  {
    "objectID": "cleaning.html#distribution",
    "href": "cleaning.html#distribution",
    "title": "3  Step 2. Standarizing your data",
    "section": "3.2 Distribution",
    "text": "3.2 Distribution\nhere"
  },
  {
    "objectID": "cleaning.html#ecology",
    "href": "cleaning.html#ecology",
    "title": "3  Step 2. Standarizing your data",
    "section": "3.3 Ecology",
    "text": "3.3 Ecology\nhere"
  },
  {
    "objectID": "intro.html#expect-result",
    "href": "intro.html#expect-result",
    "title": "1  Introduction",
    "section": "1.3 Expect result",
    "text": "1.3 Expect result\nA data that is: - accurate - comprehensive - consistent - relevant - uniform"
  },
  {
    "objectID": "preparation.html#initial-clean-up",
    "href": "preparation.html#initial-clean-up",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.6 Initial clean-up",
    "text": "2.6 Initial clean-up\nRemove records from doubtful sources. Sometimes the source iof the data is questionable and it’s better to discard it straight form the beginning: from drawings, photographs or multimedia objects."
  },
  {
    "objectID": "preparation.html#rebuild-missing-data",
    "href": "preparation.html#rebuild-missing-data",
    "title": "2  Step 1. Download and prepare your data",
    "section": "2.7 Rebuild missing data",
    "text": "2.7 Rebuild missing data"
  },
  {
    "objectID": "intro.html#characteristics-of-a-quality-data",
    "href": "intro.html#characteristics-of-a-quality-data",
    "title": "1  Introduction",
    "section": "1.2 Characteristics of a quality data",
    "text": "1.2 Characteristics of a quality data\n\nAccurate. describe here\nComprehensive. describe here\nConsistent. describe here\nRelevant. describe here\nUniform. describe here\n\nfrom (https://www.iteratorshq.com/blog/data-cleaning-in-5-easy-steps/)"
  },
  {
    "objectID": "intro.html#data-cleaning-process",
    "href": "intro.html#data-cleaning-process",
    "title": "1  Introduction",
    "section": "1.3 Data cleaning process",
    "text": "1.3 Data cleaning process\nIn the next chapters you will take a deep dive into the different steps of the data cleaning process. In can be separated into three main steps: Data preparition, standarization and enrichment (Figure 1).\n\n\n\nFigure 1. Data cleaning process"
  },
  {
    "objectID": "intro.html#importance-of-data-cceaning",
    "href": "intro.html#importance-of-data-cceaning",
    "title": "1  Introduction",
    "section": "1.1 Importance of data Cceaning",
    "text": "1.1 Importance of data Cceaning\nData cleaning is a process of identifying, fixing or/and removing incorrect, doubtful, mislabeled, or incomplete data within a dataset. It is a critical step in any research on biodiversity, as it guarantees the most trustful data to perform analyses for research. The anecdote “garbage in, garbage out” reflects this idea - a study analysis is as good as the data used.\nData problems can come from many sources, from the precision of the coordinate points during collection in the field to the combination of multiple data sources, where mismatches can happen. For this reason, the data cleaning process will vary from different datasets, making it hard to point out a “work for all” solution.\nAlthough data cleaning can be time-consuming, an established and consistent process will result in quality data to be used in future analyses."
  }
]